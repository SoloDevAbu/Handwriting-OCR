{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwriting OCR System Demo\n",
    "\n",
    "This notebook demonstrates how to use the Handwriting OCR system for text recognition from images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add the backend source directory to Python path\n",
    "sys.path.append(str(Path.cwd().parent / 'backend' / 'src'))\n",
    "\n",
    "from preprocessing.image_processor import preprocess_image\n",
    "from model.ocr_model import OCRModel\n",
    "from inference.predictor import predict_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the OCR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OCR model\n",
    "model = OCRModel()\n",
    "print(\"Model initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_with_regions(image, regions=None):\n",
    "    \"\"\"Display image with detected text regions\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    if regions:\n",
    "        for (x1, y1, x2, y2) in regions:\n",
    "            plt.gca().add_patch(plt.Rectangle(\n",
    "                (x1, y1), x2-x1, y2-y1,\n",
    "                fill=False, color='red', linewidth=2\n",
    "            ))\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process a Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process a sample image\n",
    "def process_sample_image(image_path):\n",
    "    # Read image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Could not load image from {image_path}\")\n",
    "    \n",
    "    # Preprocess image\n",
    "    processed = preprocess_image(cv2.imencode('.png', image)[1].tobytes())\n",
    "    \n",
    "    # Detect text regions\n",
    "    regions = model.detect_text_regions(processed)\n",
    "    \n",
    "    # Display original image with detected regions\n",
    "    print(\"Original image with detected text regions:\")\n",
    "    display_image_with_regions(image, regions)\n",
    "    \n",
    "    # Display preprocessed image\n",
    "    print(\"\\nPreprocessed image:\")\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(processed, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Perform OCR\n",
    "    text = predict_text(model, processed)\n",
    "    print(\"\\nRecognized Text:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(text)\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it with your own image!\n",
    "\n",
    "Replace the image path below with your own handwritten text image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "image_path = \"path/to/your/image.jpg\"  # Replace with your image path\n",
    "recognized_text = process_sample_image(image_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
